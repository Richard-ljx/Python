# å•ç›®ç›¸æœºæ ¡æ­£ï¼šæµ‹é‡ç›¸æœºç„¦è·å’Œä¾¿å®œä¸»è¦çš„åŸç†æ˜¯å¼ æ­£å‹æ ‡å®šæ³•ï¼Œæµ‹é‡ç•¸å˜å‚æ•°æ˜¯Brownç®—æ³•
import cv2 as cv
import numpy as np
import glob
from matplotlib import pyplot as plt
from image_merge import plt_pic


# ç›¸æœºæ ¡æ­£
def camera_calibration(img_path, corner_size):     # corner_sizeç±»å‹ä¸º(w_num, h_num)
    w_num, h_num = corner_size       # w_num, h_numåˆ†åˆ«æ˜¯æ£‹ç›˜æ ¼æ¨¡æ¿é•¿è¾¹å’ŒçŸ­è¾¹è§„æ ¼ï¼ˆè§’ç‚¹ä¸ªæ•°ï¼‰

    # ä¸–ç•Œåæ ‡ç³»ä¸­çš„æ£‹ç›˜æ ¼ç‚¹,ä¾‹å¦‚(0,0,0), (1,0,0), (2,0,0) ....,(8,5,0)ï¼Œå»æ‰Zåæ ‡,è®°ä¸ºäºŒç»´çŸ©é˜µ,è®¤ä¸ºåœ¨æ£‹ç›˜æ ¼è¿™ä¸ªå¹³é¢ä¸ŠZ=0
    objp = np.zeros((w_num*h_num, 3), np.float32)     # æ„é€ 0çŸ©é˜µï¼Œ88è¡Œ3åˆ—ï¼Œç”¨äºå­˜æ”¾è§’ç‚¹çš„ä¸–ç•Œåæ ‡
    objp[:, :2] = np.mgrid[0:w_num,0:h_num].T.reshape(-1, 2)    # np.mgrid[è¿”å›å¤šç»´ç»“æ„ï¼Œå¸¸è§çš„å¦‚2Då›¾å½¢ï¼Œ3Då›¾å½¢ã€‚  .Tæ˜¯è½¬ç½®

    # æ‰¾æ£‹ç›˜æ ¼è§’ç‚¹ï¼Œé˜ˆå€¼
    # criteriaï¼š(type,max_iter,epsilon)è¿™æ˜¯è¿­ä»£ç»ˆæ­¢æ¡ä»¶ã€‚æ»¡è¶³æ­¤æ¡ä»¶åï¼Œç®—æ³•è¿­ä»£å°†åœæ­¢ã€‚
    # a. typeç»ˆæ­¢æ¡ä»¶çš„ç±»å‹ï¼›b. max_iter-ä¸€ä¸ªæ•´æ•°ï¼ŒæŒ‡å®šæœ€å¤§è¿­ä»£æ¬¡æ•°ï¼› c. epsilon-è¦æ±‚çš„ç²¾åº¦ã€‚
    # typeå…·æœ‰3ä¸ªæ ‡å¿—ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
    #     cv.TERM_CRITERIA_EPS-å¦‚æœè¾¾åˆ°æŒ‡å®šçš„ç²¾åº¦epsilonï¼Œåˆ™åœæ­¢ç®—æ³•è¿­ä»£ã€‚
    #     cv.TERM_CRITERIA_MAX_ITER-åœ¨æŒ‡å®šçš„è¿­ä»£æ¬¡æ•°max_iterä¹‹ååœæ­¢ç®—æ³•ã€‚
    #     cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER-å½“æ»¡è¶³ä¸Šè¿°ä»»ä½•æ¡ä»¶æ—¶ï¼Œåœæ­¢è¿­ä»£ã€‚
    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)    # criteria = (1 + 2, 30, 0.001)

    # å‚¨å­˜æ£‹ç›˜æ ¼è§’ç‚¹çš„ä¸–ç•Œåæ ‡å’Œå›¾åƒåæ ‡å¯¹
    objpoints = [] # åœ¨ä¸–ç•Œåæ ‡ç³»ä¸­çš„ä¸‰ç»´ç‚¹
    imgpoints = [] # åœ¨å›¾åƒå¹³é¢çš„äºŒç»´ç‚¹
    images = glob.glob(img_path)
    for fname in images:
        img = cv.imread(fname)

        if img is None:
            print("æ— æ³•è¯»å–(%s)å›¾ç‰‡"  %fname)
            return -1

        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
        # ç²—ç•¥æ‰¾åˆ°æ£‹ç›˜æ ¼è§’ç‚¹ è¿™é‡Œæ‰¾åˆ°çš„æ˜¯è¿™å¼ å›¾ç‰‡ä¸­è§’ç‚¹çš„äºšåƒç´ ç‚¹ä½ç½®ï¼Œå…±11Ã—8 = 88ä¸ªç‚¹ï¼Œgrayå¿…é¡»æ˜¯8ä½ç°åº¦æˆ–è€…å½©è‰²å›¾ï¼Œï¼ˆw,hï¼‰ä¸ºè§’ç‚¹è§„æ¨¡
        ret, corners = cv.findChessboardCorners(gray, (w_num, h_num))    # corners.shape=(w*h, 1, 2)
        # å¦‚æœæ‰¾åˆ°è¶³å¤Ÿç‚¹å¯¹ï¼Œå°†å…¶å­˜å‚¨èµ·æ¥
        if ret:
            # ç²¾ç¡®æ‰¾åˆ°è§’ç‚¹åæ ‡
            corners = cv.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)

            # å°†è§’ç‚¹åœ¨å›¾åƒä¸Šæ˜¾ç¤º
            cv.drawChessboardCorners(img, (w_num, h_num), corners, ret)
            # cv.namedWindow('findCorners', cv.WINDOW_NORMAL)
            # cv.imshow('findCorners', img)
            # key = cv.waitKey(0) & 0xFF     # 0xFFæ˜¯åè¿›åˆ¶çš„255
            key = ord("o")

            print("è¯·ç¡®å®šæ­¤å¼ å›¾ç‰‡è§’ç‚¹ä½ç½®æ˜¯å¦æ­£ç¡®(æ­£ç¡®è¯·æŒ‰â€œoâ€ï¼Œå¦åˆ™è¯·æŒ‰â€œEscâ€)")
            # å¦‚æœæŒ‰ä¸‹é”®ç›˜çš„"o"é”®ï¼Œåˆ™è®¤ä¸ºæ­¤å¼ å›¾è§’ç‚¹æ£€æµ‹æ­£ç¡®
            if key == ord("o"):    # ord()å‡½æ•°ä¸»è¦ç”¨æ¥è¿”å›å¯¹åº”å­—ç¬¦çš„asciiç 
                # å°†æ­£ç¡®çš„objpç‚¹æ”¾å…¥objpointsä¸­
                objpoints.append(objp)
                imgpoints.append(corners)

    if not objpoints or not imgpoints:
        return -1
    cv.destroyAllWindows()

    # ç›¸æœºæ ‡å®šå‡½æ•°
    # retè¡¨ç¤ºçš„æ˜¯é‡æŠ•å½±è¯¯å·®ï¼›mtxæ˜¯ç›¸æœºçš„å†…å‚çŸ©é˜µï¼›distè¡¨è¿°çš„ç›¸æœºç•¸å˜å‚æ•°ï¼›
    # rvecsè¡¨ç¤ºæ ‡å®šæ£‹ç›˜æ ¼ä¸–ç•Œåæ ‡ç³»åˆ°ç›¸æœºåæ ‡ç³»çš„æ—‹è½¬å‚æ•°ï¼šrotation vectorsï¼Œéœ€è¦è¿›è¡Œç½—å¾·é‡Œæ ¼æ–¯è½¬æ¢ï¼›
    # tvecsè¡¨ç¤ºtranslation vectorsï¼Œä¸»è¦æ˜¯å¹³ç§»å‚æ•°ã€‚
    retval, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, criteria)
    print("é‡æŠ•å½±è¯¯å·®:%f" %retval)

    # æ˜¯è°ƒèŠ‚è§†åœºå¤§å°ï¼Œä¸º1æ—¶è§†åœºå¤§å°ä¸å˜ï¼Œå°äº1æ—¶ç¼©æ”¾è§†åœº; alpha=0ï¼Œè§†åœºä¼šæ”¾å¤§ï¼Œalpha=1ï¼Œè§†åœºä¸å˜
    newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, gray.shape[::-1], 0, gray.shape[::-1])

    # é‡æŠ•å½±è¯¯å·®
    total_error = 0
    for i in range(len(objpoints)):
        imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)
        error = cv.norm(imgpoints[i],imgpoints2, cv.NORM_L2) ** 2
        total_error += error
    print( "é‡æŠ•å½±è¯¯å·®: {}".format(np.sqrt(total_error/(len(objpoints)*len(imgpoints2)))))

    # è¿”å›å€¼ï¼šé‡æŠ•å½±è¯¯å·®ï¼Œ å†…å‚çŸ©é˜µï¼Œ ç•¸å˜å‚æ•°ï¼Œ æ—‹è½¬çŸ©é˜µï¼Œ å¹³ç§»çŸ©é˜µï¼Œ ä¸‰ç»´åæ ‡ç‚¹ï¼Œ äºŒä½åæ ‡ç‚¹
    return (mtx, dist, newcameramtx, roi, objpoints, imgpoints)


# ä¼˜åŒ–æ ¡æ­£åçš„ç³»æ•°å¹¶å¯¹å•å¼ å›¾ç‰‡æ ¡æ­£
def undistorted_image(img_path, corner_size):
    imagesL = img_path + '/left*.jpg'
    imagesR = img_path + '/right*.jpg'
    valL = camera_calibration(imagesL, corner_size)
    valR = camera_calibration(imagesR, corner_size)
    if valL == -1 or valR == -1:
        print("æœªæ£€æµ‹åˆ°ä»»ä½•ä¸€å¼ è§’ç‚¹å›¾ç‰‡")
        return -1
    mtxL, distL, newcameramtxL, roiL, objpointsL, imgpointsL = valL
    mtxR, distR, newcameramtxR, roiR, objpointsR, imgpointsR = valR

    imgL1 = cv.imread(img_path + '/left1.jpg')
    imgR1 = cv.imread(img_path + '/right1.jpg')
    img = cv.cvtColor(imgL1, cv.COLOR_BGR2GRAY)

    # åŒç›®ç›¸æœºçš„æ ‡å®š
    # è®¾ç½®æ ‡å¿—ä½ä¸ºcv2.CALIB_FIX_INTRINSICï¼Œè¿™æ ·å°±ä¼šå›ºå®šè¾“å…¥çš„cameraMatrixå’ŒdistCoeffsä¸å˜ï¼Œåªæ±‚è§£ğ‘…,ğ‘‡,ğ¸,ğ¹
    flags = 0
    flags |= cv.CALIB_FIX_INTRINSIC
    # è®¾ç½®è¿­ä»£ç»ˆæ­¢æ¡ä»¶
    criteria_stereo = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)

    retS, MLS, dLS, MRS, dRS, R, T, E, F = cv.stereoCalibrate(objpointsL, imgpointsL, imgpointsR, newcameramtxL, distL,
                                         newcameramtxR, distR, img.shape[::-1], criteria_stereo, flags)

    # åˆ©ç”¨stereoRectify()è®¡ç®—ç«‹ä½“æ ¡æ­£çš„æ˜ å°„çŸ©é˜µ
    rectify_scale = 1  # è®¾ç½®ä¸º0çš„è¯ï¼Œå¯¹å›¾ç‰‡è¿›è¡Œå‰ªè£ï¼Œè®¾ç½®ä¸º1åˆ™ä¿ç•™æ‰€æœ‰åŸå›¾åƒåƒç´ 
    RL, RR, PL, PR, Q, roiL, roiR = cv.stereoRectify(MLS, dLS, MRS, dRS,
                                                      img.shape[::-1], R, T, rectify_scale, (0, 0))
    # åˆ©ç”¨initUndistortRectifyMapå‡½æ•°è®¡ç®—ç•¸å˜çŸ«æ­£å’Œç«‹ä½“æ ¡æ­£çš„æ˜ å°„å˜æ¢ï¼Œå®ç°æçº¿å¯¹é½ã€‚
    Left_Stereo_Map = cv.initUndistortRectifyMap(MLS, dLS, RL, PL,
                                                  img.shape[::-1], cv.CV_16SC2)

    dstL = cv.undistort(imgL1, mtxL, distL, None, newcameramtxL)
    dstR = cv.undistort(imgR1, mtxL, distL, None, newcameramtxL)

    # æ ¹æ®å‰é¢ROIåŒºåŸŸè£å‰ªå›¾ç‰‡,åˆ©ç”¨ä¸‹é¢çš„undistorted_videoå‡½æ•°è§‚çœ‹æ›´æ˜æ˜¾
    x, y, w, h = roiL
    dst_cropL = dstL[y:y+h, x:x+w]
    dst_cropR = dstR[y:y+h, x:x+w]

    img12 = np.hstack((imgL1, imgR1))
    dst = np.hstack((dstL, dstR))
    dst_crop = np.hstack((dst_cropL, dst_cropR))

    # åœ¨å·²ç»æçº¿å¯¹é½çš„å›¾ç‰‡ä¸Šå‡åŒ€ç”»çº¿
    for i in range(1, 20):
        len = 480 / 20
        plt.axhline(y=i * len, color='r', linestyle='-')

    image_dict = {'åŸå§‹å›¾åƒ': img12, 'æ ¡æ­£å›¾åƒ': dst, 'è£å‰ªåæ ¡æ­£å›¾åƒ': dst_crop}
    plt_pic(image_dict, arrangement=1)


# ä¼˜åŒ–æ ¡æ­£åçš„ç³»æ•°å¹¶å¯¹è§†é¢‘è¿›è¡Œæ ¡æ­£
def undistorted_video(img_path, corner_size):
    val = camera_calibration(img_path, corner_size)
    if val == -1:
        print("æœªæ£€æµ‹åˆ°ä»»ä½•ä¸€å¼ è§’ç‚¹å›¾ç‰‡")
        return -1
    mtx, dist = val


    capture = cv.VideoCapture(0)  # åˆ›å»ºä¸€ä¸ª VideoCapture å¯¹è±¡

    if not capture.isOpened():
        print("æ‘„åƒå¤´æ‰“å¼€å¤±è´¥")
        return -1

    while True:
        ret, img = capture.read()
        h, w = img.shape[:2]
        newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))

        dst = cv.undistort(img, mtx, dist, None, newcameramtx)
        cv.imshow('dst', dst)

        # æ ¹æ®å‰é¢ROIåŒºåŸŸè£æ‰å›¾åƒå‘¨å›´çš„é»‘è¾¹
        x, y, w, h = roi
        dst = dst[y:y + h, x:x + w]
        cv.imshow('dst_crop', dst)

        key = cv.waitKey(20) & 0xFF
        if key == 27:
            break
    capture.release()
    cv.destroyAllWindows()


if __name__ == "__main__":
    path = r'./images'
    undistorted_image(path, (9, 6))
    # undistorted_video(path, (9, 6))
